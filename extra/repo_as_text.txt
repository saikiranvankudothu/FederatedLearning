Repository: https://github.com/faresmalik/FeSViBS.git
Files analyzed: 9

Directory structure:
└── faresmalik-FeSViBS/
    ├── Figures
    │   └── method.PNG
    ├── .gitignore
    ├── centralized.py
    ├── dataset.py
    ├── FeSViBS.py
    ├── LICENSE
    ├── local.py
    ├── models.py
    ├── README.md
    ├── requirements.txt
    ├── SLViT.py
    └── utils.py


================================================
FILE: FeSViBS.py
================================================
import os 
import numpy as np
import models 
import random
from dataset import skinCancer, bloodmnisit, isic2019
from utils import weight_dec_global, weight_vec
import argparse 
import torch as torch
from torch import nn




def fesvibs(
        dataset_name, lr, batch_size, Epochs, input_size, num_workers, save_every_epochs, 
        model_name, pretrained, opt_name, seed, base_dir, root_dir, csv_file_path, num_clients, DP, 
        epsilon, delta, resnet_dropout, initial_block, final_block, fesvibs_arg, local_round
        ):

    torch.manual_seed(seed)
    random.seed(seed)
    np.random.seed(seed)

    if fesvibs_arg: 
        method_flag = 'FeSViBS'
    else:
        method_flag = 'SViBS'

    if torch.cuda.is_available():
        device = 'cuda'
    else: 
        device = 'cpu'

    if DP:
        std = np.sqrt(2 * np.math.log(1.25/delta)) / epsilon 
        mean=0
        dir_name = f"{model_name}_{lr}lr_{dataset_name}_{num_clients}Clients_{initial_block}to{final_block}Blocks_{batch_size}Batch__{epsilon,delta}DP_{method_flag}"
    else:
        mean = 0
        std = 0
        dir_name = f"{model_name}_{lr}lr_{dataset_name}_{num_clients}Clients_{initial_block}to{final_block}Blocks_{batch_size}Batch_{method_flag}"

    save_dir = f'{dir_name}' 
    os.mkdir(save_dir)    

    print(f"Logging to: {dir_name}")

    print('Getting the Dataset and Dataloader!')
    if dataset_name == 'HAM': 
        num_classes = 7
        _, _, traindataset, testdataset = skinCancer(input_size= input_size, batch_size = batch_size, base_dir= base_dir, num_workers=num_workers)
        num_channels = 3

    elif dataset_name == 'bloodmnist':
        num_classes = 8
        _, _, traindataset, testdataset = bloodmnisit(input_size= input_size, batch_size = batch_size, download= True, num_workers=num_workers)
        num_channels = 3

    elif dataset_name == 'isic2019': 
        num_classes = 8
        DATALOADERS, _, _, _, _, test_loader = isic2019(input_size= input_size, batch_size = batch_size, root_dir=root_dir, csv_file_path=csv_file_path, num_workers=num_workers)
        num_channels = 3

    criterion = nn.CrossEntropyLoss()

    fesvibs_network = models.FeSVBiS(
            ViT_name= model_name, num_classes= num_classes,
            num_clients = num_clients, in_channels = num_channels,
            ViT_pretrained= pretrained,
            initial_block= initial_block, final_block= final_block,
            resnet_dropout= resnet_dropout, DP=DP, mean= mean, std= std
            ).to(device)
    
    Split = models.SplitFeSViBS(
        num_clients=num_clients, device = device, network = fesvibs_network, 
        criterion = criterion, base_dir=save_dir, 
        initial_block= initial_block, final_block= final_block,
        )
    

    if dataset_name != 'isic2019':
        print('Distribute Images Among Clients')
        Split.distribute_images(dataset_name=dataset_name, train_data= traindataset,test_data= testdataset ,batch_size = batch_size)  
    else: 
        Split.CLIENTS_DATALOADERS = DATALOADERS
        Split.testloader = test_loader

    Split.set_optimizer(opt_name, lr = lr)
    Split.init_logs()

    print('Start Training! \n')

    for r in range(Epochs):
        print(f"Round {r+1} / {Epochs}")
        agg_weights = None
        for client_i in range(num_clients):
            weight_dict = Split.train_round(client_i)
            if client_i == 0: 
                agg_weights = weight_dict
            else: 
                agg_weights['blocks'] +=  weight_dict['blocks']
                agg_weights['cls'] +=  weight_dict['cls']
                agg_weights['pos_embed'] +=  weight_dict['pos_embed']
                
        agg_weights['blocks'] /= num_clients
        agg_weights['cls'] /= num_clients
        agg_weights['pos_embed'] /= num_clients  

        
        Split.network.vit.blocks = weight_dec_global(
            Split.network.vit.blocks,
            agg_weights['blocks'].to(device)
            )
        
        Split.network.vit.cls_token.data = agg_weights['cls'].to(device) + 0.0
        Split.network.vit.pos_embed.data = agg_weights['pos_embed'].to(device) + 0.0

        if fesvibs_arg and ((r+1) % local_round == 0 and r!= 0):
                print('========================== \t \t Federation \t \t ==========================')
                tails_weights = []
                head_weights = []
                for head, tail in zip(Split.network.resnet50_clients, Split.network.mlp_clients_tail):
                    head_weights.append(weight_vec(head).detach().cpu())
                    tails_weights.append(weight_vec(tail).detach().cpu())
                
                mean_avg_tail = torch.mean(torch.stack(tails_weights), axis = 0)
                mean_avg_head = torch.mean(torch.stack(head_weights), axis = 0)

                for i in range(num_clients):
                    Split.network.mlp_clients_tail[i] = weight_dec_global(Split.network.mlp_clients_tail[i], 
                                                                        mean_avg_tail.to(device))
                    Split.network.resnet50_clients[i] = weight_dec_global(Split.network.resnet50_clients[i], 
                                                                        mean_avg_head.to(device))
       
        for client_i in range(num_clients):
            Split.eval_round(client_i)
            
        print('---------')

        if (r+1) % save_every_epochs == 0 and r != 0: 
            Split.save_pickles(save_dir)
        print('============================================')

if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='Run Centralized Experiments')
    parser.add_argument('--dataset_name', type=str, choices=['HAM', 'bloodmnist', 'isic2019'], help='Dataset Name')
    parser.add_argument('--input_size',  type=int, default= 224, help='Input size --> (input_size, input_size), default : 224')
    parser.add_argument('--local_round',  type=int, default= 2, help='Local round before federation in FeSViBS, default : 2')
    parser.add_argument('--num_workers',  type=int, default= 8, help='Number of workers for dataloaders, default : 8')
    parser.add_argument('--initial_block',  type=int, default= 1, help='Initial Block, default : 1')
    parser.add_argument('--final_block',  type=int, default= 6, help='Final Block, default : 6')
    parser.add_argument('--num_clients',  type=int, default= 6, help='Number of Clients, default : 6')
    parser.add_argument('--model_name', type=str, default= 'vit_base_r50_s16_224', help='Model name from timm library, default: vit_base_r50_s16_224')
    parser.add_argument('--pretrained', type=bool, default= False, help='Pretrained weights flag, default: False')
    parser.add_argument('--fesvibs_arg', type=bool, default= False, help='Flag to indicate whether SViBS or FeSViBS, default: False')
    parser.add_argument('--batch_size',  type=int, default= 32, help='Batch size, default : 32')
    parser.add_argument('--Epochs',  type=int, default= 200, help='Number of Epochs, default : 200')
    parser.add_argument('--opt_name', type=str, choices=['Adam'], default = 'Adam', help='Optimizer name, only ADAM optimizer is available')
    parser.add_argument('--lr',  type=float, default= 1e-4, help='Learning rate, default : 1e-4')
    parser.add_argument('--save_every_epochs',  type=int, default= 10, help='Save metrics every this number of epochs, default: 10')
    parser.add_argument('--seed',  type=int, default= 105, help='Seed, default: 105')
    parser.add_argument('--base_dir', type=str, default= None, help='')
    parser.add_argument('--root_dir', type=str, default= None, help='')
    parser.add_argument('--csv_file_path', type=str, default=None, help='')
    parser.add_argument('--DP', type=bool, default= False, help='Differential Privacy , default: False')
    parser.add_argument('--epsilon',  type=float, default= 0, help='Epsilon Value for differential privacy')
    parser.add_argument('--delta',  type=float, default= 0.00001, help='Delta Value for differential privacy')
    parser.add_argument('--resnet_dropout',  type=float, default= 0.5, help='ResNet Dropout, Default: 0.5')
    args = parser.parse_args()

    fesvibs(
        dataset_name = args.dataset_name, input_size= args.input_size, 
        num_workers= args.num_workers, model_name= args.model_name, 
        pretrained= args.pretrained, batch_size= args.batch_size, 
        Epochs= args.Epochs, opt_name= args.opt_name, lr= args.lr, 
        save_every_epochs= args.save_every_epochs, seed= args.seed, 
        base_dir= args.base_dir, root_dir= args.root_dir, csv_file_path= args.csv_file_path,  num_clients = args.num_clients, 
        DP = args.DP, epsilon = args.epsilon, delta = args.delta, initial_block= args.initial_block, final_block=args.final_block,
        resnet_dropout = args.resnet_dropout, fesvibs_arg = args.fesvibs_arg, local_round = args.local_round
        )

================================================
FILE: README.md
================================================
# FeSViBS
Source code for MICCAI 2023 paper entitled: 'FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling'


<hr/>

![Method](Figures/method.PNG)

## Abstract
Data scarcity is a significant obstacle hindering the learning of powerful machine learning models in critical healthcare applications. Data-sharing mechanisms among multiple entities (e.g., hospitals) can accelerate model training and yield more accurate predictions. Recently, approaches such as Federated Learning (FL) and Split Learning (SL) have facilitated collaboration without the need to exchange private data. In this work, we propose a framework for medical imaging classification tasks called Federated Split learning of Vision transformer with Block Sampling (FeSViBS). The FeSViBS framework builds upon the existing federated split vision transformer and introduces a \emph{block sampling} module, which leverages intermediate features extracted by the Vision Transformer (ViT) at the server. This is achieved by sampling features (patch tokens) from an intermediate transformer block and distilling their information content into a pseudo class token before passing them back to the client. These pseudo class tokens serve as an effective feature augmentation strategy and enhances the generalizability of the learned model. We demonstrate the utility of our proposed method compared to other SL and FL approaches on three publicly available medical imaging datasets: HAM1000, BloodMNIST, and Fed-ISIC2019, under both IID and non-IID settings.

## Install Dependinces
Install all dependincies by running the following command: 

```
pip install -r requirements.txt

```

## Datasets

We conduct all experiments on **three** datasets: 

1. HAM10000 [3] -- Can be downloaded from [here](https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000?select=HAM10000_images_part_2)
2. Blood cells (BloodMNIST) -- MedMnist library [1]
3. Federated version of ISIC2019 dataset -- FLamby library [2]

For the Federated ISIC2019 dataset, the path to __ISIC_2019_Training_Input_preprocessed__ directory and __train_test_split__  csv file, are required to run different methods on this dataset

## Running Centralized Training/Testing
In order to run  **Centralized Training** run the following command: 

```
python centralized.py  --dataset_name [choose the dataset name] --opt_name [default is Adam] --lr [learning rate] --seed [seed number] --base_dir [path data folder for HAM] --save_every_epochs [Save pickle files] --root_dir [Path to ISIC_2019_Training_Input_preprocessed for ISIC2019]  --csv_file_path [Path to train_test_split csv for ISIC2019] --Epochs [Number of Epochs]

```


## Running Local Training/Testing for Each Client
In order to run  **Local Training/Testing** run the following command: 

```
python local.py  --local_arg True --dataset_name [choose the dataset name] --opt_name [default is Adam] --lr [learning rate] --seed [seed number] --base_dir [path data folder for HAM] --save_every_epochs [Save pickle files] --root_dir [Path to ISIC_2019_Training_Input_preprocessed for ISIC2019]  --csv_file_path [Path to train_test_split csv for ISIC2019] --num_clients [Number of clients] --Epochs [Number of Epochs]

```

## Running Vanilla Split Learning with Vision Transformers (SLViT)
In order to run  **SLViT without** Differential Privacy (DP) run the following command: 

```
python SLViT.py --dataset_name [choose the dataset name] --opt_name [default is Adam] --lr [learning rate] --seed [seed number] --base_dir [path data folder for HAM] --save_every_epochs [Save pickle files] --root_dir [Path to ISIC_2019_Training_Input_preprocessed for ISIC2019]  --csv_file_path [Path to train_test_split csv for ISIC2019] --num_clients [Number of clients] --Epochs [Number of Epochs]

```

**SLViT with** Differential Privacy (DP) run the following command:

```
python SLViT.py --DP True --epsilon [epsilon value] --delta [delta value] --dataset_name [choose the dataset name] --opt_name [default is Adam] --lr [learning rate] --seed [seed number] --base_dir [path data folder for HAM] --save_every_epochs [Save pickle files] --root_dir [Path to ISIC_2019_Training_Input_preprocessed for ISIC2019] --csv_file_path [Path to train_test_split csv for ISIC2019] --num_clients [Number of clients] --Epochs [Number of Epochs] 

```

## Running Split Vision Transformer with Block Sampling (SViBS):
In order to run  **SViBS** run the following command: 

```
python FeSViBS.py --dataset_name [choose the dataset name] --opt_name [default is Adam] --lr [learning rate] --seed [seed number] --base_dir [path data folder for HAM] --save_every_epochs [Save pickle files] --root_dir [Path to ISIC_2019_Training_Input_preprocessed for ISIC2019]  --csv_file_path [Path to train_test_split csv for ISIC2019] --num_clients [Number of clients] --Epochs [Number of Epochs] --initial_block 1 --final_block 6 

```

## Running Federated Split Vision Transformer with Block Sampling (FeSViBS):
In order to run  **FeSViBS without** Differential Privacy (DP) run the following command: 

```
python FeSViBS.py --fesvibs_arg True --local_round [number of local rounds before federation] --dataset_name [choose the dataset name] --opt_name [default is Adam] --lr [learning rate] --seed [seed number] --base_dir [path data folder for HAM] --save_every_epochs [Save pickle files] --root_dir [Path to ISIC_2019_Training_Input_preprocessed for ISIC2019]  --csv_file_path [Path to train_test_split csv for ISIC2019] --num_clients [Number of clients] --Epochs [Number of Epochs] --initial_block 1 --final_block 6 

```

In order to run  **FeSViBS with** Differential Privacy (DP) run the following command: 

```
python FeSViBS.py --fesvibs_arg True --DP True --epsilon [epsilon value] --delta [delta value] --local_round [number of local rounds before federation] --dataset_name [choose the dataset name] --opt_name [default is Adam] --lr [learning rate] --seed [seed number] --base_dir [path data folder for HAM] --save_every_epochs [Save pickle files] --root_dir [Path to ISIC_2019_Training_Input_preprocessed for ISIC2019]  --csv_file_path [Path to train_test_split csv for ISIC2019] --num_clients [Number of clients] --Epochs [Number of Epochs] --initial_block 1 --final_block 6 

```
## Citation
```
@misc{almalik2023fesvibs,
      title={FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling}, 
      author={Faris Almalik and Naif Alkhunaizi and Ibrahim Almakky and Karthik Nandakumar},
      year={2023},
      eprint={2306.14638},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

```
## References 

[1] Yang, J., Shi, R., Ni, B.: Medmnist classification decathlon: A lightweight automl benchmark for medical image analysis. In: IEEE 18th International Symposium on Biomedical Imaging (ISBI). pp. 191–195 (2021) 

[2] du Terrail, J.O., Ayed, S.S., Cyffers, E., Grimberg, F., He, C., Loeb, R., Mangold, P., Marchand, T., Marfoq, O., Mushtaq, E., Muzellec, B., Philippenko, C., Silva, S., Teleńczuk, M., Albarqouni, S., Avestimehr, S., Bellet, A., Dieuleveut, A., Jaggi, M., Karimireddy, S.P., Lorenzi, M., Neglia, G., Tommasi, M., Andreux, M.: FLamby: Datasets and benchmarks for cross-silo federated learning in realistic healthcare settings. In: Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (2022)

[3] Tschandl, P., Rosendahl, C., Kittler, H.: The ham10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. Scientific Data 5(11), 180161 (Aug 2018).


================================================
FILE: SLViT.py
================================================
import os
import torch 
import numpy as np
from torch import nn
import random 
from models import SLViT, SplitNetwork
from dataset import skinCancer, bloodmnisit, isic2019
import argparse 
from utils import weight_dec_global

def slvit(dataset_name, lr, batch_size, Epochs, input_size, num_workers, save_every_epochs, model_name, pretrained, opt_name, seed , base_dir, root_dir, csv_file_path, num_clients, DP, epsilon, delta):

    np.random.seed(seed)
    torch.manual_seed(seed)
    random.seed(seed)

    if torch.cuda.is_available():
        device = 'cuda'
    else:
        device = 'cpu'

    mean = 0 
    std  = 1
    if DP: 
        std = np.sqrt(2 * np.math.log(1.25/delta)) / epsilon 

    save_dir = f'{model_name}_{lr}lr_{dataset_name}_{num_clients}Clients_{DP}DP_{batch_size}Batch_SLViT'

    if DP: 
        save_dir = f'{model_name}_{lr}lr_{dataset_name}_{num_clients}Clients_({epsilon}, {delta})DP_{batch_size}Batch_SLViT'
    
    os.mkdir(save_dir)

    print('Getting the Dataset and Dataloader!')
    if dataset_name == 'HAM': 
        num_classes = 7
        _, _, traindataset, testdataset = skinCancer(input_size= input_size, batch_size = batch_size, base_dir= base_dir, num_workers=num_workers)
        num_channels = 3

    elif dataset_name == 'bloodmnist':
        num_classes = 8
        _, _, traindataset, testdataset = bloodmnisit(input_size= input_size, batch_size = batch_size, download= True, num_workers=num_workers)
        num_channels = 3

    elif dataset_name == 'isic2019': 
        num_classes = 8
        DATALOADERS, _, _, _, _, test_loader = isic2019(input_size= input_size, batch_size = batch_size, root_dir=root_dir, csv_file_path=csv_file_path, num_workers=num_workers)
        num_channels = 3

    slvit = SLViT(
        ViT_name= model_name, num_classes=num_classes,
        num_clients=num_clients, in_channels=num_channels,
        ViT_pretrained = pretrained,
        diff_privacy=DP, mean=mean, std = std
    ).to(device)

    criterion = nn.CrossEntropyLoss()

    Split = SplitNetwork(
        num_clients=num_clients, device = device, 
        network = slvit, criterion = criterion, base_dir=save_dir,
        )

    print('Distribute Data')
    if dataset_name != 'isic2019':  
        Split.distribute_images(dataset_name=dataset_name, train_data=traindataset, test_data=testdataset , batch_size = batch_size)  
    else:
        Split.CLIENTS_DATALOADERS  = DATALOADERS
        Split.testloader = test_loader

    Split.set_optimizer(opt_name, lr = lr)
    Split.init_logs()

    for r in range(Epochs):
        print(f"Round {r+1} / {Epochs}")
        agg_weights = None
        for client_i in range(num_clients):
            weight_dict = Split.train_round(client_i)
            if client_i ==0: 
                agg_weights = weight_dict
            else: 
                agg_weights['blocks'] +=  weight_dict['blocks']
                agg_weights['cls'] +=  weight_dict['cls']
                agg_weights['pos_embed'] +=  weight_dict['pos_embed']
        
        agg_weights['blocks'] /= num_clients
        agg_weights['cls'] /= num_clients
        agg_weights['pos_embed'] /= num_clients    

        Split.network.vit.blocks = weight_dec_global(
            Split.network.vit.blocks,
            agg_weights['blocks'].to(device)
            )
        
        Split.network.vit.cls_token.data = agg_weights['cls'].to(device) + 0.0
        Split.network.vit.pos_embed.data = agg_weights['pos_embed'].to(device) + 0.0
        
        for client_i in range(num_clients):
            Split.eval_round(client_i)
        
        print('---------')
        
        if (r+1) % save_every_epochs == 0 and r != 0: 
            Split.save_pickles(save_dir)

        print('============================================')

if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='Run Centralized Experiments')

    parser.add_argument('--dataset_name', type=str, choices=['HAM', 'bloodmnist', 'isic2019'], help='Dataset Name')
    parser.add_argument('--input_size',  type=int, default= 224, help='Input size --> (input_size, input_size), default : 224')
    parser.add_argument('--num_workers',  type=int, default= 8, help='Number of workers for dataloaders, default : 8')
    parser.add_argument('--num_clients',  type=int, default= 6, help='Number of Clients, default : 6')
    parser.add_argument('--model_name', type=str, default= 'vit_base_r50_s16_224', help='Model name from timm library, default: vit_base_r50_s16_224')
    parser.add_argument('--pretrained', type=bool, default= False, help='Pretrained weights flag, default: False')
    parser.add_argument('--batch_size',  type=int, default= 32, help='Batch size, default : 32')
    parser.add_argument('--Epochs',  type=int, default= 200, help='Number of Epochs, default : 200')
    parser.add_argument('--opt_name', type=str, choices=['Adam'], default = 'Adam', help='Optimizer name, only ADAM optimizer is available')
    parser.add_argument('--lr',  type=float, default= 1e-4, help='Learning rate, default : 1e-4')
    parser.add_argument('--save_every_epochs',  type=int, default= 10, help='Save metrics every this number of epochs, default: 10')
    parser.add_argument('--seed',  type=int, default= 105, help='Seed, default: 105')
    parser.add_argument('--base_dir', type=str, default= None, help='')
    parser.add_argument('--root_dir', type=str, default= None, help='')
    parser.add_argument('--csv_file_path', type=str, default=None, help='')
    parser.add_argument('--DP', type=bool, default= False, help='Differential Privacy , default: False')
    parser.add_argument('--epsilon',  type=float, default= 0, help='Epsilon Value for differential privacy')
    parser.add_argument('--delta',  type=float, default= 0.00001, help='Delta Value for differential privacy')


    args = parser.parse_args()

    slvit(
        dataset_name = args.dataset_name, input_size= args.input_size, 
        num_workers= args.num_workers, model_name= args.model_name, 
        pretrained= args.pretrained, batch_size= args.batch_size, 
        Epochs= args.Epochs, opt_name= args.opt_name, lr= args.lr, 
        save_every_epochs= args.save_every_epochs, seed= args.seed, 
        base_dir= args.base_dir, root_dir= args.root_dir, csv_file_path= args.csv_file_path,  num_clients = args.num_clients, 
        DP = args.DP, epsilon = args.epsilon, delta = args.delta
        )

================================================
FILE: centralized.py
================================================
import timm 
import torch
import dataset
import os 
import random
import numpy as np 
from curses.ascii import FF
from models import CentralizedFashion
from torch import nn
import argparse

from dataset import skinCancer, bloodmnisit, isic2019


def centralized(dataset_name, lr, batch_size, Epochs, input_size, num_workers, save_every_epochs, model_name, pretrained, opt_name, seed , base_dir, root_dir, csv_file_path):

    torch.manual_seed(seed)
    random.seed(seed)
    np.random.seed(seed)


    if torch.cuda.is_available():
        device = 'cuda'
    else:
        device = 'cpu'


    print('Creating Loggings Directory!')
    save_dir = f'{model_name}_{lr}lr_{dataset_name}_{Epochs}rounds_Centralized'
    os.mkdir(save_dir)

    print('Getting the Dataset and Dataloader!')
    if dataset_name == 'HAM': 
        num_classes = 7
        train_loader, test_loader,_,_ = skinCancer(input_size= input_size, batch_size = batch_size, base_dir= base_dir, num_workers=num_workers)
        num_channels = 3

    elif dataset_name == 'bloodmnist':
        num_classes = 8
        train_loader, test_loader,_,_ = bloodmnisit(input_size= input_size, batch_size = batch_size, download= True, num_workers=num_workers)
        num_channels = 3

    elif dataset_name == 'isic2019': 
        num_classes = 8
        _, _, train_loader, _, _, test_loader = isic2019(input_size= input_size, batch_size = batch_size, root_dir=root_dir, csv_file_path=csv_file_path, num_workers=num_workers)
        num_channels = 3

    print('Getting the model from timm library!')
    model = timm.create_model(
        model_name= model_name, pretrained= pretrained,
        num_classes = num_classes, in_chans=num_channels
        ).to(device)


    criterion = torch.nn.CrossEntropyLoss()

    centralized_network = CentralizedFashion(
        device= device, network=model, criterion= criterion,
        base_dir=save_dir
        )

    #Instantiate metrics and set optimizer
    centralized_network.init_logs()
    centralized_network.set_optimizer(name=opt_name, lr = lr)

    print(f'Train Centralized Fashion:\n model: {model_name}\n dataset: {dataset_name}\n LR: {lr}\n Number of Epochs: {Epochs}\n Loggings: {save_dir}\n')
    print('Start Training! \n')

    #Training and Evaluation Loop
    for r in range(Epochs):
        print(f"Round {r+1} / {Epochs}")
        centralized_network.train_round(train_loader)
        centralized_network.eval_round(test_loader)
        print('---------')
        if (r+1) % save_every_epochs == 0 and r != 0: 
            centralized_network.save_pickles(save_dir)
        print('============================================')


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='Run Centralized Experiments')

    parser.add_argument('--dataset_name', type=str, choices=['HAM', 'bloodmnist', 'isic2019'], help='Dataset Name')
    parser.add_argument('--input_size',  type=int, default= 224, help='Input size --> (input_size, input_size), default : 224')
    parser.add_argument('--num_workers',  type=int, default= 8, help='Number of workers for dataloaders, default : 8')
    parser.add_argument('--model_name', type=str, default= 'vit_base_r50_s16_224', help='Model name from timm library, default: vit_base_r50_s16_224')
    parser.add_argument('--pretrained', type=bool, default= False, help='Pretrained weights flag, default: False')
    parser.add_argument('--batch_size',  type=int, default= 32, help='Batch size, default : 32')
    parser.add_argument('--Epochs',  type=int, default= 200, help='Number of Epochs, default : 200')
    parser.add_argument('--opt_name', type=str, choices=['Adam'], default = 'Adam', help='Optimizer name, only ADAM optimizer is available')
    parser.add_argument('--lr',  type=float, default= 1e-4, help='Learning rate, default : 1e-4')
    parser.add_argument('--save_every_epochs',  type=int, default= 10, help='Save metrics every this number of epochs, default: 10')
    parser.add_argument('--seed',  type=int, default= 105, help='Seed, default: 105')
    parser.add_argument('--base_dir', type=str, default= None, help='')
    parser.add_argument('--root_dir', type=str, default= None, help='')
    parser.add_argument('--csv_file_path', type=str, default=None, help='')

    args = parser.parse_args()

    centralized(
        dataset_name = args.dataset_name, input_size= args.input_size, 
        num_workers= args.num_workers, model_name= args.model_name, 
        pretrained= args.pretrained, batch_size= args.batch_size, 
        Epochs= args.Epochs, opt_name= args.opt_name, lr= args.lr, 
        save_every_epochs= args.save_every_epochs, seed= args.seed, 
        base_dir= args.base_dir, root_dir= args.root_dir, csv_file_path= args.csv_file_path
        )

================================================
FILE: dataset.py
================================================
import sys
import os
import glob

import numpy as np 

from PIL import Image
from torch.utils.data import DataLoader
from torchvision import transforms
import torch.utils.data as data
import torch 

import medmnist
from medmnist import INFO

from utils import get_data, CustomDataset, ISIC2019, blood_noniid, distribute_data

import random 

seed = 105
np.random.seed(seed)
torch.manual_seed(seed)
random.seed(seed)


def distribute_images(dataset_name,train_data, num_clients, test_data, batch_size, num_workers = 8):
    """
    This method splits the dataset among clients.
    train_data: train dataset 
    test_data: test dataset 
    batch_size: batch size

    """
    if dataset_name == 'HAM':
        CLIENTS_DATALOADERS = distribute_data(num_clients, train_data, batch_size)
        testloader = torch.utils.data.DataLoader(test_data,batch_size=batch_size, num_workers= num_workers)

    elif dataset_name == 'bloodmnist':
        _, testloader, train_dataset, _ = bloodmnisit(batch_size= batch_size)
        _, CLIENTS_DATALOADERS, _ = blood_noniid(num_clients, train_dataset, batch_size =batch_size)
        
    return CLIENTS_DATALOADERS, testloader

def bloodmnisit(input_size =224, batch_size = 32, num_workers= 8, download = True):
    """
        Get train/test loaders and sets for bloodmnist from medmnist library. 

        Input: 
            input_size (int): width of the input image which issimilar to height 
            batch_size (int)
            num_workers (int): Num of workeres used for in creating the loaders 
            download (bool): Whether to download the dataset or not
        
        return: 
            train_loader, test_loader, train_dataset, test_dataset
    """

    data_flag = 'bloodmnist'
    info = INFO[data_flag]
    DataClass = getattr(medmnist, info['python_class'])

    data_transform_train = transforms.Compose([
        transforms.RandomVerticalFlip(),
        transforms.RandomHorizontalFlip(),
        transforms.RandomAffine(degrees= 10, translate=(0.1,0.1)),
        transforms.RandomResizedCrop(input_size, (0.75,1), (0.9,1)), 
        transforms.ToTensor(),
        ]) 
    
    data_transform_teest = transforms.Compose([
        transforms.Resize(224), 
        transforms.ToTensor(),
        ])
    
    train_dataset = DataClass(split='train', transform=data_transform_train, download=download)
    test_dataset = DataClass(split='test', transform=data_transform_teest, download=download)

    train_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*batch_size, shuffle=False, num_workers=num_workers)
    
    return train_loader, test_loader, train_dataset, test_dataset

def skinCancer(input_size = 224, batch_size = 32, base_dir = './data', num_workers = 8):
    """
        Get the SkinCancer datasets and dataloaders. 

        Input:
            input_size (int): width of the input image
            batch_size (int)
            base_dir (str): Path to directory which includes the skincancer images
            num_workers (int): for dataloaders 
        
        return: 
            train_loader, testing_loader, train_dataset, test_dataset
    
    """
    all_image_path = glob.glob(os.path.join(base_dir, '*.jpg'))
    imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}
    df_train, df_val = get_data(base_dir, imageid_path_dict)

    normMean = [0.76303697, 0.54564005, 0.57004493]
    normStd = [0.14092775, 0.15261292, 0.16997]

    train_transform = transforms.Compose([transforms.RandomResizedCrop((input_size,input_size), scale=(0.9,1.1)),
                                          transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),
                                          transforms.RandomRotation(10),
                                          transforms.RandomHorizontalFlip(),
                                          transforms.ToTensor(),
                                          transforms.Normalize(normMean, normStd)])

    # define the transformation of the val images.
    val_transform = transforms.Compose([transforms.Resize((input_size,input_size)),
                                        transforms.ToTensor(),
                                        transforms.Normalize(normMean, normStd)])

    training_set = CustomDataset(df_train.drop_duplicates('image_id'), transform=train_transform)
    train_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)

    # Same for the validation set:
    validation_set = CustomDataset(df_val.drop_duplicates('image_id'), transform=val_transform)
    val_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)
    
    return train_loader, val_loader, training_set, validation_set

def isic2019(input_size = 224, root_dir = './ISIC_2019_Training_Input_preprocessed', csv_file_path = './train_test_split', batch_size = 32, num_workers=8):
    
    """
        Function that return train and test dataloaders and datasets fir centralized training and federated settings. 

        Input: 
            root_dir (str): path to directory that has preproceessed images from FLamby library
            csv_file_path (str): Path to the csv file that has train_test_split as per FLamby Library
        
        Return: 
            Clients train dataloaders (federated), Clients test loaders, Train dataloader (centralized), 
            Clients train datasets (Federated), Clients test datasets (Federated), Test dataloader (All testing images in one loader) 
    """
    clients_datasets_train = [
        ISIC2019(
        csv_file_path= csv_file_path, 
        root_dir=root_dir,client_id=i,train=True, centralized=False, input_size= input_size) for i in range(6)
    ]
    
    test_datasets = [
         ISIC2019(
        csv_file_path= csv_file_path, 
        root_dir=root_dir, client_id=i, train=False, centralized=False, input_size= input_size) for i in range(6)
        
    ]
    
    centralized_dataset_train = ISIC2019(
        csv_file_path= csv_file_path, 
        root_dir=root_dir, client_id=None ,train=True, centralized=True, input_size= input_size
    )
    
    clients_dataloader_train = [
        DataLoader(
        dataset=clients_datasets_train[i],batch_size= batch_size, shuffle=True, num_workers=num_workers
        ) for i in range(6)
    ]
    
    test_dataloaders = [
        DataLoader(dataset=test_datasets[i],batch_size= batch_size, shuffle=False, num_workers=num_workers)
        for i in range(6)
    ]

    test_centralized_dataset =  ISIC2019(
        csv_file_path= csv_file_path, 
        root_dir=root_dir, client_id=None , train=False, centralized=True, input_size= input_size
        )

    test_dataloader_centralized = DataLoader(dataset=test_centralized_dataset,batch_size= batch_size, shuffle=False, num_workers=num_workers)

    
    centralized_dataloader_train = DataLoader(dataset=centralized_dataset_train,batch_size= batch_size, shuffle=True, num_workers=num_workers)

    return clients_dataloader_train, test_dataloaders, centralized_dataloader_train, clients_datasets_train, test_datasets, test_dataloader_centralized

================================================
FILE: local.py
================================================
import os 
import timm
import torch 
import numpy as np
from torch import nn
import os
import random 
import argparse 

from models import CentralizedFashion
from dataset import skinCancer, bloodmnisit, isic2019, distribute_images


def local(dataset_name, lr, batch_size, Epochs, input_size, num_workers, save_every_epochs, model_name, pretrained, opt_name, seed, base_dir, root_dir, csv_file_path, num_clients, local_arg):

    np.random.seed(seed)
    torch.manual_seed(seed)
    random.seed(seed)

    if torch.cuda.is_available():
        device = 'cuda'
    else:
        device = 'cpu'

    print('Load Dataset and DataLoader!')
    if dataset_name == 'HAM': 
        num_classes = 7
        train_loader, test_loader, train_data, test_data = skinCancer(input_size= input_size, batch_size = batch_size, base_dir= base_dir, num_workers=num_workers)
        num_channels = 3

    elif dataset_name == 'bloodmnist':
        num_classes = 8
        train_loader, test_loader, train_data, test_data = bloodmnisit(input_size= input_size, batch_size = batch_size, download= True, num_workers=num_workers)
        num_channels = 3

    elif dataset_name == 'isic2019': 
        num_classes = 8
        DATALOADERS, _, _, _, _, test_loader = isic2019(input_size= input_size, batch_size = batch_size, root_dir=root_dir, csv_file_path=csv_file_path, num_workers=num_workers)
        num_channels = 3
        


    print('Create Directory for metrics loggings!')
    save_dir = f'{model_name}_{lr}lr_{dataset_name}_{Epochs}rounds_Local'
    os.mkdir(save_dir)

    print(f'Train Local Fashion:\n Number of Clients :{num_clients}\n model: {model_name}\n dataset: {dataset_name}\n LR: {lr}\n Number of Epochs: {Epochs}\n Loggings: {save_dir}\n')

    if dataset_name in ['HAM', 'bloodmnist']:
        print(f'Distribute Dataset Among {num_clients} Clients')

        DATALOADERS, test_loader = distribute_images(
            dataset_name = dataset_name, train_data = train_data, num_clients= num_clients,
            test_data = test_data, batch_size = batch_size, num_workers= num_workers
            )

    print('Loading Model form timm Library for All clients!')
    model = [timm.create_model(
        model_name= model_name, 
        num_classes= num_classes, 
        in_chans = num_channels, 
        pretrained= pretrained,
    ).to(device) for i in range(num_clients)]
                
    criterion = nn.CrossEntropyLoss()

    local = [CentralizedFashion(
        device = device,
        network = model[i], criterion = criterion,
        base_dir = save_dir
    ) for i in range(num_clients)]


    for i in range(num_clients):
        local[i].set_optimizer(opt_name, lr = lr)
        local[i].init_logs()

    for r in range(Epochs):
        print(f"Round {r+1} / {Epochs}")
        for client_i in range(num_clients):
            print(f'Client {client_i+1} / {num_clients}')
            local[client_i].train_round(DATALOADERS[client_i])
            local[client_i].eval_round(test_loader)
            print('---------')
            if (r+1) % save_every_epochs == 0 and r != 0: 
                local[client_i].save_pickles(save_dir,local= local_arg, client_id=client_i+1) 
        print('============================================')


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='Run Centralized Experiments')

    parser.add_argument('--dataset_name', type=str, choices=['HAM', 'bloodmnist', 'isic2019'], help='Dataset Name')
    parser.add_argument('--num_clients',  type=int, default= 6, help='Number of clients, default : 6')
    parser.add_argument('--local_arg', type=bool, default= True, help='Local Argument, default: True')
    parser.add_argument('--input_size',  type=int, default= 224, help='Input size --> (input_size, input_size), default : 224')
    parser.add_argument('--num_workers',  type=int, default= 8, help='Number of workers for dataloaders, default : 8')
    parser.add_argument('--model_name', type=str, default= 'vit_base_r50_s16_224', help='Model name from timm library, default: vit_base_r50_s16_224')
    parser.add_argument('--pretrained', type=bool, default= False, help='Pretrained weights flag, default: False')
    parser.add_argument('--batch_size',  type=int, default= 32, help='Batch size, default : 32')
    parser.add_argument('--Epochs',  type=int, default= 200, help='Number of Epochs, default : 200')
    parser.add_argument('--opt_name', type=str, choices=['Adam'], default = 'Adam', help='Optimizer name, only ADAM optimizer is available')
    parser.add_argument('--lr',  type=float, default= 1e-4, help='Learning rate, default : 1e-4')
    parser.add_argument('--save_every_epochs',  type=int, default= 10, help='Save metrics every this number of epochs, default: 10')
    parser.add_argument('--seed',  type=int, default= 105, help='Seed, default: 105')
    parser.add_argument('--base_dir', type=str, default= None, help='')
    parser.add_argument('--root_dir', type=str, default= None, help='')
    parser.add_argument('--csv_file_path', type=str, default=None, help='')

    args = parser.parse_args()

    local(
        dataset_name = args.dataset_name, num_clients= args.num_clients, 
        input_size= args.input_size, local_arg= args.local_arg, 
        num_workers= args.num_workers, model_name= args.model_name, 
        pretrained= args.pretrained, batch_size= args.batch_size, 
        Epochs= args.Epochs, opt_name= args.opt_name, lr= args.lr, 
        save_every_epochs= args.save_every_epochs, seed= args.seed, 
        base_dir= args.base_dir, root_dir= args.root_dir, csv_file_path= args.csv_file_path
        )

================================================
FILE: models.py
================================================
from tqdm import tqdm
import pickle as pkl
import os 
import timm 
import copy 
import numpy as np 

import torch.nn as nn 
import torch 
from sklearn.metrics import balanced_accuracy_score

from dataset import blood_noniid, bloodmnisit, distribute_data
from utils import weight_vec

class CentralizedFashion(): 
    def __init__(self, device, network, criterion, base_dir):
        """
            Class for Centralized Paradigm.    
            args:
                device: cuda vs cpu
                network: ViT model
                criterion: loss function to be used
                base_dir: where to save metrics as pickles
            return: 
                None 
        """
        self.device = device
        self.network = network
        self.criterion = criterion
        self.base_dir = base_dir

    def set_optimizer(self, name, lr):
        """
        name: Optimizer name, e.g. Adam 
        lr: learning rate 

        """
        if name == 'Adam':
            self.optimizer = torch.optim.Adam(self.network.parameters(), lr = lr)

    def init_logs(self):
            """
            A method to initialize dictionaries for the metrics
            return : None 
            args: None
            """
            self.losses  = {'train':[], 'test':[]}
            self.balanced_accs = {'train':[], 'test':[]}

    def train_round(self, train_loader):
        """
        Training loop. 

        """
        running_loss = 0
        whole_labels = []
        whole_preds = []
        whole_probs = []
        for imgs, labels in tqdm(train_loader): 
            self.optimizer.zero_grad()
            imgs, labels = imgs.to(self.device),labels.to(self.device)
            output = self.network(imgs)
            labels = labels.reshape(labels.shape[0])
            loss = self.criterion(output, labels)
            loss.backward()
            self.optimizer.step()
            running_loss += loss.item() 
            _, predicted = torch.max(output, 1)
            whole_probs.append(torch.nn.Softmax(dim = -1)(output).detach().cpu())
            whole_labels.append(labels.detach().cpu())
            whole_preds.append(predicted.detach().cpu())    
        self.metrics(whole_labels, whole_preds, running_loss, len(train_loader), whole_probs, train = True)
        
    def eval_round(self, test_loader):
        """
        Evaluation loop. 

        client_i: Client index.
                
        """
        running_loss = 0
        whole_labels = []
        whole_preds = []
        whole_probs = []
        with torch.no_grad():
            for imgs, labels in tqdm(test_loader): 
                imgs, labels = imgs.to(self.device), labels.to(self.device)
                output = self.network(imgs)
                labels = labels.reshape(labels.shape[0])
                loss = self.criterion(output, labels)
                running_loss += loss.item() 
                _, predicted = torch.max(output, 1)
                whole_probs.append(torch.nn.Softmax(dim = -1)(output).detach().cpu())
                whole_labels.append(labels.detach().cpu())
                whole_preds.append(predicted.detach().cpu())    
            self.metrics(whole_labels, whole_preds, running_loss, len(test_loader), whole_probs, train= False)
    
    def metrics(self, whole_labels, whole_preds, running_loss, len_loader, whole_probs, train):
        """
        Save metrics as pickle files and the model as .pt file.
        
        """
        whole_labels = torch.cat(whole_labels)
        whole_preds = torch.cat(whole_preds)
        loss_epoch = running_loss/len_loader
        balanced_acc = balanced_accuracy_score(whole_labels.detach().cpu(),whole_preds.detach().cpu())
        if train == True:
            eval_name = 'train'
        else:
            eval_name = 'test'

        self.losses[eval_name].append(loss_epoch)
        self.balanced_accs[eval_name].append(balanced_acc)
        
        print(f"{eval_name}:")
        print(f"{eval_name}_loss :{loss_epoch:.3f}")
        print(f"{eval_name}_balanced_acc :{balanced_acc:.3f}")


    def save_pickles(self, base_dir, local= None, client_id=None): 
        if local and client_id: 
            with open(os.path.join(base_dir,f'loss_epoch_Client{client_id}'), 'wb') as handle:
                pkl.dump(self.losses, handle)
            with open(os.path.join(base_dir,f'balanced_accs{client_id}'), 'wb') as handle:
                pkl.dump(self.balanced_accs, handle)
        else: 
            with open(os.path.join(base_dir,'loss_epoch'), 'wb') as handle:
                pkl.dump(self.losses, handle)
            with open(os.path.join(base_dir,f'balanced_accs'), 'wb') as handle:
                pkl.dump(self.balanced_accs, handle)

class SLViT(nn.Module): 
    def __init__(
        self, ViT_name, num_classes , num_clients=6, 
        in_channels=3, ViT_pretrained = False,
        diff_privacy = False, mean = 0, std = 1
        ) -> None:

        super().__init__()

        self.vit = timm.create_model(
            model_name = ViT_name,
            pretrained = ViT_pretrained,
            num_classes = num_classes,
            in_chans = in_channels
        )   
        client_tail = MLP_cls_classes(num_classes= num_classes)
        self.mlp_clients_tail =  nn.ModuleList([copy.deepcopy(client_tail)for i in range(num_clients)])
        self.resnet50_clients = nn.ModuleList([copy.deepcopy(self.vit.patch_embed) for i in range(num_clients)]) 
        
        self.diff_privacy = diff_privacy
        self.mean = mean 
        self.std = std

    def forward(self, x, client_idx):
        x = self.resnet50_clients[client_idx](x)
        if self.diff_privacy == True:
            noise = torch.randn(size= x.shape).cuda() * self.std + self.mean
            x = x + noise
        x = torch.cat((self.vit.cls_token.expand(x.shape[0], -1, -1), x), dim=1)
        x = self.vit.pos_drop(x + self.vit.pos_embed)
        for block_num in range(12):
            x = self.vit.blocks[block_num](x)
        x = self.vit.norm(x)
        cls = self.vit.pre_logits(x)[:,0,:]
        x = self.mlp_clients_tail[client_idx](cls)
        return x, cls

class MLP_cls_classes(nn.Module):
    def __init__(self,num_classes):
        super().__init__()
        self.norm = nn.LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        self.identity = nn.Identity()
        self.fc = nn.Linear(in_features=768, out_features=num_classes, bias=True)

    def forward(self, x):
        x = self.norm(x)
        x = self.identity(x)
        x = self.fc(x)
        return x 

class SplitNetwork():
    def __init__(
        self, num_clients, device, network, 
        criterion, base_dir,
        ):
        """
        args:
            num_clients
            device: cuda vs cpu
            network: ViT model
            criterion: loss function to be used
            base_dir: where to save pickles/model files
        """
        
        self.device = device
        self.num_clients = num_clients
        self.criterion = criterion
        self.network = network
        self.base_dir = base_dir

    def init_logs(self):
        """
        This method initializes dictionaries for the metrics

        """
        self.losses  = {'train':[[] for i in range(self.num_clients)], 'test':[[] for i in range(self.num_clients)]}
        self.balanced_accs = {'train':[[] for i in range(self.num_clients)], 'test':[[] for i in range(self.num_clients)]}

    def set_optimizer(self, name, lr):
        """
        name: Optimizer name, e.g. Adam 
        lr: learning rate 

        """
        if name == 'Adam':
            self.optimizer = torch.optim.Adam(self.network.parameters(), lr = lr)
    
    def distribute_images(self, dataset_name ,train_data, test_data, batch_size):
        """
        This method splits the dataset among clients.
        train_data: train dataset 
        test_data: test dataset 
        batch_size: batch size

        """
        if dataset_name == 'HAM':
            self.CLIENTS_DATALOADERS = distribute_data(self.num_clients, train_data, batch_size)
            self.testloader = torch.utils.data.DataLoader(test_data,batch_size=batch_size, num_workers= 8)
            
        elif dataset_name == 'bloodmnist':
            _, self.testloader, train_dataset, _ = bloodmnisit(batch_size= batch_size)
            _, self.CLIENTS_DATALOADERS, _ = blood_noniid(self.num_clients, train_dataset, batch_size =batch_size)  

    def train_round(self, client_i):
        """
        Training loop. 

        client_i: Client index.

        """
        running_loss_client_i = 0
        mel_running_loss = 0
        whole_labels = []
        whole_preds = []
        whole_probs = []
        copy_network = copy.deepcopy(self.network)
        weight_dic = {'blocks':None, 'cls':None, 'pos_embed':None}
        self.network.train()
        for data in tqdm(self.CLIENTS_DATALOADERS[client_i]): 
            self.optimizer.zero_grad()
            imgs, labels = data[0].to(self.device), data[1].to(self.device)
            labels = labels.reshape(labels.shape[0])
            tail_output = self.network(imgs, client_i)
            loss = self.criterion(tail_output[0], labels)
            loss.backward()
            self.optimizer.step()
            running_loss_client_i+= loss.item() 
            _, predicted = torch.max(tail_output[0], 1)
            whole_probs.append(torch.nn.Softmax(dim = -1)(tail_output[0]).detach().cpu())
            whole_labels.append(labels.detach().cpu())
            whole_preds.append(predicted.detach().cpu()) 
        self.metrics(client_i, whole_labels, whole_preds, running_loss_client_i, len(self.CLIENTS_DATALOADERS[client_i]), whole_probs, train = True)
        
        # if self.avg_body:
        weight_dic['blocks'] = weight_vec(self.network.vit.blocks).detach().cpu()
        weight_dic['cls'] = self.network.vit.cls_token.detach().cpu()
        weight_dic['pos_embed'] = self.network.vit.pos_embed.detach().cpu()

        self.network.vit.blocks = copy.deepcopy(copy_network.vit.blocks)
        self.network.vit.cls_token = copy.deepcopy(copy_network.vit.cls_token)
        self.network.vit.pos_embed =  copy.deepcopy(copy_network.vit.pos_embed)
        return weight_dic
            
    def eval_round(self, client_i):
        """
        Evaluation loop. 

        client_i: Client index.
                
        """
        running_loss_client_i = 0
        whole_labels = []
        whole_preds = []
        whole_probs = []
        self.network.eval()
        with torch.no_grad():
            for data in tqdm(self.testloader): 
                imgs, labels = data[0].to(self.device), data[1].to(self.device)
                tail_output = self.network(imgs, client_i)[0]
                labels = labels.reshape(labels.shape[0])
                loss = self.criterion(tail_output, labels)
                running_loss_client_i+= loss.item() 
                _, predicted = torch.max(tail_output, 1)
                whole_probs.append(torch.nn.Softmax(dim = -1)(tail_output).detach().cpu())
                whole_labels.append(labels.detach().cpu())
                whole_preds.append(predicted.detach().cpu())    
            self.metrics(client_i, whole_labels, whole_preds, running_loss_client_i, len(self.testloader), whole_probs, train= False)

    def metrics(self, client_i, whole_labels, whole_preds, running_loss_client_i, len_loader, whole_probs, train):
        """
        Save metrics as pickle files and the model as .pt file.
        
        """
        whole_labels = torch.cat(whole_labels)
        whole_preds = torch.cat(whole_preds)
        loss_epoch = running_loss_client_i/len_loader
        balanced_acc = balanced_accuracy_score(whole_labels.detach().cpu(), whole_preds.detach().cpu())
       
        if train == True:
            eval_name = 'train'
        else:
            eval_name = 'test'

        self.losses[eval_name][client_i].append(loss_epoch)
        self.balanced_accs[eval_name][client_i].append(balanced_acc)

        print(f"client{client_i}_{eval_name}:")
        print(f" Loss {eval_name}:{loss_epoch:.3f}")
        print(f"balanced accuracy {eval_name}:{balanced_acc:.3f}")

    def save_pickles(self, base_dir): 
        with open(os.path.join(base_dir,'loss_epoch'), 'wb') as handle:
            pkl.dump(self.losses, handle)
        with open(os.path.join(base_dir,'balanced_accs'), 'wb') as handle:
            pkl.dump(self.balanced_accs, handle)

class FeSVBiS(nn.Module): 
    def __init__(
        self, ViT_name, num_classes,
        num_clients=6, in_channels=3, ViT_pretrained=False, 
        initial_block=1, final_block=6, resnet_dropout = None, DP = False, mean = None, std = None
        ) -> None:
        super().__init__()

        self.initial_block = initial_block
        self.final_block = final_block

        self.vit = timm.create_model(
            model_name = ViT_name,
            pretrained = ViT_pretrained,
            num_classes = num_classes,
            in_chans = in_channels
        )   

        self.resnet50 = self.vit.patch_embed
        self.resnet50_clients = nn.ModuleList([copy.deepcopy(self.resnet50) for i in range(num_clients)])
        self.common_network = ResidualBlock(drop_out=resnet_dropout)
        client_tail = MLP_cls_classes(num_classes= num_classes)
        self.mlp_clients_tail =  nn.ModuleList([copy.deepcopy(client_tail) for i in range(num_clients)])
        self.DP = DP
        self.mean = mean
        self.std = std

    def forward(self, x, chosen_block, client_idx):
        x = self.resnet50_clients[client_idx](x)
        if self.DP: 
            noise = torch.randn(size= x.shape).cuda() * self.std + self.mean
            x = x + noise
        for block_num in range(chosen_block):
            x = self.vit.blocks[block_num](x)
        x = self.common_network(x)
        x = self.mlp_clients_tail[client_idx](x)
        return x


class ResidualBlock(nn.Module):
    def __init__(self, in_channels=768, out_channels=768, stride = 1, downsample = None, drop_out= None):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Sequential(
                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),
                        nn.BatchNorm2d(out_channels),
                        nn.ReLU())
        self.conv2 = nn.Sequential(
                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),
                        nn.BatchNorm2d(out_channels))
        self.downsample = downsample
        self.relu = nn.ReLU()
        self.out_channels = out_channels
        self.pool = nn.AvgPool2d(14, stride=1)
        self.dropout = nn.Dropout2d(p=drop_out)
        self.drop_out = drop_out

    def forward(self, x):
        if len(x.shape) == 3: 
            x = torch.permute(x,(0,-1,1))
            x = x.reshape(x.shape[0], x.shape[1] , 14, 14)
        residual = x
        out = self.conv1(x)
        if self.drop_out is not None: 
            out = self.dropout(out)
        out = self.conv2(out)
        if self.downsample:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        out = self.pool(out)
        return out.reshape(-1,768)

class SplitFeSViBS(SplitNetwork):
    def __init__(
        self, num_clients, device, 
        network, criterion, base_dir, 
        initial_block, final_block,
        ):

        self.initial_block = initial_block
        self.final_block   = final_block    
        self.num_clients = num_clients
        self.device = device
        self.network = network
        self.criterion = criterion
        self.base_dir = base_dir
        self.train_chosen_blocks = [0] * num_clients

    def set_optimizer_mel(self, name, lr):
        if name == 'Adam':
            self.optimizer_mel = [torch.optim.Adam(self.mel_body[i].parameters(), lr = lr) for i in range(self.num_clients)]

    def train_round(self, client_i):
        """
        Training loop. 

        client_i: Client index.

        """
        running_loss_client_i = 0
        whole_labels = []
        whole_preds = []
        whole_probs = []
        self.chosen_block = np.random.randint(low = self.initial_block, high= self.final_block+1) 
        self.train_chosen_blocks[client_i] =  self.chosen_block
        copy_network = copy.deepcopy(self.network)
        weight_dic = {}
        weight_dic['blocks'] = None
        weight_dic['cls'] = None
        weight_dic['pos_embed'] = None
        weight_dic['resnet'] = None
        print(f"Chosen Block:{self.chosen_block} for client {client_i}")
        self.network.train()
        for data in tqdm(self.CLIENTS_DATALOADERS[client_i]): 
            self.optimizer.zero_grad()
            imgs, labels = data[0].to(self.device), data[1].to(self.device)
            labels = labels.reshape(labels.shape[0])
            tail_output = self.network(x=imgs, chosen_block=self.chosen_block, client_idx = client_i)
            loss = self.criterion(tail_output, labels)
            loss.backward()
            self.optimizer.step()
            running_loss_client_i+= loss.item() 
            _, predicted = torch.max(tail_output, 1)
            whole_probs.append(torch.nn.Softmax(dim = -1)(tail_output).detach().cpu())
            whole_labels.append(labels.detach().cpu())
            whole_preds.append(predicted.detach().cpu()) 
        self.metrics(client_i, whole_labels, whole_preds, running_loss_client_i, len(self.CLIENTS_DATALOADERS[client_i]), whole_probs, train = True)
        
        weight_dic['blocks'] = weight_vec(self.network.vit.blocks).detach().cpu()
        weight_dic['cls'] = self.network.vit.cls_token.detach().cpu()
        weight_dic['pos_embed'] = self.network.vit.pos_embed.detach().cpu()
        
        self.network.vit.blocks = copy.deepcopy(copy_network.vit.blocks)
        self.network.vit.cls_token = copy.deepcopy(copy_network.vit.cls_token)
        self.network.vit.pos_embed =  copy.deepcopy(copy_network.vit.pos_embed)
        return weight_dic
    
    
    def eval_round(self, client_i):
        """
        Evaluation loop. 

        client_i: Client index.
                
        """
        running_loss_client_i = 0
        whole_labels = []
        whole_preds = []
        whole_probs = []
        num_b = self.train_chosen_blocks[client_i]
        print(f"Chosen block for testing: {num_b}")
        self.network.eval()
        with torch.no_grad():
            for data in tqdm(self.testloader): 
                imgs, labels = data[0].to(self.device), data[1].to(self.device)
                labels = labels.reshape(labels.shape[0])
                tail_output = self.network(x=imgs, chosen_block=num_b, client_idx = client_i)
                loss = self.criterion(tail_output, labels)
                running_loss_client_i+= loss.item() 
                _, predicted = torch.max(tail_output, 1)
                whole_probs.append(torch.nn.Softmax(dim = -1)(tail_output).detach().cpu())
                whole_labels.append(labels.detach().cpu())
                whole_preds.append(predicted.detach().cpu())    
            self.metrics(client_i, whole_labels, whole_preds, running_loss_client_i, len(self.testloader), whole_probs, train= False)


================================================
FILE: requirements.txt
================================================
asttokens==2.0.5
backcall==0.2.0
certifi==2022.12.7
charset-normalizer==3.1.0
cmake==3.26.0
comm==0.1.2
contourpy==1.0.7
cycler==0.11.0
debugpy==1.5.1
decorator==5.1.1
entrypoints==0.4
executing==0.8.3
filelock==3.10.0
fire==0.5.0
fonttools==4.39.0
idna==3.4
imageio==2.26.0
ipykernel==6.19.2
ipython==8.10.0
jedi==0.18.1
Jinja2==3.1.2
joblib==1.2.0
jupyter_client==7.4.9
jupyter_core==5.2.0
kiwisolver==1.4.4
lazy_loader==0.1
lit==15.0.7
MarkupSafe==2.1.2
matplotlib==3.7.1
matplotlib-inline==0.1.6
medmnist==2.1.0
mpmath==1.3.0
nest-asyncio==1.5.6
networkx==3.0
numpy==1.24.2
nvidia-cublas-cu11==11.10.3.66
nvidia-cuda-cupti-cu11==11.7.101
nvidia-cuda-nvrtc-cu11==11.7.99
nvidia-cuda-runtime-cu11==11.7.99
nvidia-cudnn-cu11==8.5.0.96
nvidia-cufft-cu11==10.9.0.58
nvidia-curand-cu11==10.2.10.91
nvidia-cusolver-cu11==11.4.0.1
nvidia-cusparse-cu11==11.7.4.91
nvidia-nccl-cu11==2.14.3
nvidia-nvtx-cu11==11.7.91
packaging==22.0
pandas==1.5.3
parso==0.8.3
pexpect==4.8.0
pickleshare==0.7.5
Pillow==9.0.1
pip==23.0.1
platformdirs==2.5.2
prompt-toolkit==3.0.36
psutil==5.9.0
ptyprocess==0.7.0
pure-eval==0.2.2
Pygments==2.11.2
pyparsing==3.0.9
python-dateutil==2.8.2
pytz==2022.7.1
PyWavelets==1.4.1
pyzmq==23.2.0
requests==2.28.2
scikit-image==0.20.0
scikit-learn==1.2.2
scipy==1.10.1
setuptools==65.6.3
six==1.16.0
stack-data==0.2.0
sympy==1.11.1
termcolor==2.2.0
threadpoolctl==3.1.0
tifffile==2023.3.15
timm==0.5.4
torch==2.0.0
torchvision==0.15.1
tornado==6.2
tqdm==4.65.0
traitlets==5.7.1
triton==2.0.0
typing_extensions==4.5.0
urllib3==1.26.15
wcwidth==0.2.5
wheel==0.38.4


================================================
FILE: utils.py
================================================
import os
import torch 

import numpy as np
import pandas as pd
from PIL import Image

from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms


def weight_vec(network):
    A = []
    for w in network.parameters():
        A.append(torch.flatten(w))
    return torch.cat(A)


def weight_dec_global(pyModel, weight_vec): 
    """
    Reshape the weight back to its original shape in pytorch and then 
    plug it to the model
    """
    c = 0
    for w in pyModel.parameters():
        m = w.numel()
        D = weight_vec[c:m+c].reshape(w.data.shape) 
        c+=m
        if w.data is None:
            w.data = D+0
        else:
            with torch.no_grad():
                w.set_( D+0 )
    return pyModel


def distribute_data(numOfClients, train_dataset, batch_size):
    """
    numOfClients: int 
    train_dataset: train_dataset (torchvision.datasets class)
    return distributed dataloaders for each client
    """
    # distribution list to fill the number of samples in each entry for each client
    distribution = []
    # rounding the number to get the number of dataset each client will get
    p = round(1/numOfClients * len(train_dataset))
    
    # the remainder data that won't be able to split if it's not an even number
    remainder_data = len(train_dataset) - numOfClients * p 
    # if the remainder data is 0 ---> all clients will get the same number of dataset
    if remainder_data == 0: 
        distribution = [p for i in range(numOfClients)]
    else:
        distribution = [p for i in range(numOfClients-1)]
        distribution.append(p+remainder_data)

    # splitting the data to different dataloaders
    data_split = torch.utils.data.random_split(train_dataset, distribution)
    # CLIENTS DATALOADERS
    ClIENTS_DATALOADERS = [torch.utils.data.DataLoader(data_split[i], batch_size=batch_size,shuffle=True, num_workers=32) for i in range(numOfClients)]
    
    print(f"Length of the training dataset: {len(train_dataset)} sample")
    return ClIENTS_DATALOADERS

def get_data(base_dir, imageid_path_dict):

    """
        Preprocessing for the SkinCancer dataset. 
        Input: 
            base_dir (str): path of the directory includes SkinCancer images
            imageid_path_dict (dict): dictionary with image id as keys and image pth as values
        
        Return: 
            df_train: Dataframe for training 
            df_val: Dataframe for testing 

    """

    lesion_type_dict = {
    'nv': 'Melanocytic nevi',
    'mel': 'dermatofibroma',
    'bkl': 'Benign keratosis-like lesions ',
    'bcc': 'Basal cell carcinoma',
    'akiec': 'Actinic keratoses',
    'vasc': 'Vascular lesions',
    'df': 'Dermatofibroma'
    }

    df_original = pd.read_csv(os.path.join(base_dir, 'HAM10000_metadata.csv'))
    df_original['path'] = df_original['image_id'].map(imageid_path_dict.get)
    df_original['cell_type'] = df_original['dx'].map(lesion_type_dict.get)
    df_original['cell_type_idx'] = pd.Categorical(df_original['cell_type']).codes

    df_original[['cell_type_idx', 'cell_type']].sort_values('cell_type_idx').drop_duplicates()

    # Get number of images associated with each lesion_id
    df_undup = df_original.groupby('lesion_id').count()
    # Filter out lesion_id's that have only one image associated with it
    df_undup = df_undup[df_undup['image_id'] == 1]
    df_undup.reset_index(inplace=True)

    # Identify lesion_id's that have duplicate images and those that have only one image.
    def get_duplicates(x):
        unique_list = list(df_undup['lesion_id'])
        if x in unique_list:
            return 'unduplicated'
        else:
            return 'duplicated'

    # create a new colum that is a copy of the lesion_id column
    df_original['duplicates'] = df_original['lesion_id']

    # apply the function to this new column
    df_original['duplicates'] = df_original['duplicates'].apply(get_duplicates)

    # Filter out images that don't have duplicates
    df_undup = df_original[df_original['duplicates'] == 'unduplicated']

    # Create a val set using df because we are sure that none of these images have augmented duplicates in the train set
    y = df_undup['cell_type_idx']
    _, df_val = train_test_split(df_undup, test_size=0.2, random_state=101, stratify=y)


    # This set will be df_original excluding all rows that are in the val set
    # This function identifies if an image is part of the train or val set.
    def get_val_rows(x):
        # create a list of all the lesion_id's in the val set
        val_list = list(df_val['image_id'])
        if str(x) in val_list:
            return 'val'
        else:
            return 'train'

    # Identify train and val rows
    # Create a new colum that is a copy of the image_id column
    df_original['train_or_val'] = df_original['image_id']
    # Apply the function to this new column
    df_original['train_or_val'] = df_original['train_or_val'].apply(get_val_rows)
    # Filter out train rows
    df_train = df_original[df_original['train_or_val'] == 'train']

    # Copy fewer class to balance the number of 7 classes
    data_aug_rate = [15,10,5,50,0,40,5]
    for i in range(7):
        if data_aug_rate[i]:
            df_train=df_train.append([df_train.loc[df_train['cell_type_idx'] == i,:]]*(data_aug_rate[i]-1), ignore_index=True)
    df_train['cell_type'].value_counts()

    df_train = df_train.reset_index()
    df_val = df_val.reset_index()

    return df_train, df_val

class CustomDataset(Dataset):
    """
        Cutom dataset for SkinCancer dataset
    """
    def __init__(self, df, transform=None):
        self.df = df
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, index):
        # Load data and get label
        X = Image.open(self.df['path'][index])
        y = torch.tensor(int(self.df['cell_type_idx'][index]))

        if self.transform:
            X = self.transform(X)
        return X, y

class ISIC2019(Dataset): 


    TO_REPLACE_TRAIN = [None, [4,5,6], None, None,[4], [4,5,6]]
    VALUES_TRAIN = [None, [3,4,5], None, None,[2], [3,4,5]]

    def __init__(self, csv_file_path, root_dir, client_id, train = True, centralized = False, input_size = 224) -> None:
        super().__init__()
        self.image_root = root_dir   
        self.train = train  
        csv_file = pd.read_csv(csv_file_path)
        self.centralized = centralized

        if train:
            if centralized: 
                self.csv = csv_file[csv_file['fold'] == 'train'].reset_index()
            else:
                self.csv = csv_file[csv_file['fold2'] == f'train_{client_id}'].reset_index()

        elif train == False:  
            if centralized: 
                self.csv = csv_file[csv_file['fold'] == 'test'].reset_index()
            else: 
                self.csv = csv_file[csv_file['fold2'] == f'test_{client_id}'].reset_index()

        if train:
            self.transform = transforms.Compose([
                transforms.RandomRotation(10), 
                transforms.RandomHorizontalFlip(0.5), 
                transforms.RandomVerticalFlip(0.5), 
                transforms.RandomAffine(degrees = 0, shear=0.05),
                transforms.RandomResizedCrop((input_size, input_size), scale=(0.85,1.1)),
                transforms.ToTensor(), 
            ])
            
        elif train == False:
           self.transform = transforms.Compose([
                    transforms.Resize((input_size, input_size)),
                    transforms.ToTensor(),
                ])
    def __len__(self):
        return self.csv.shape[0]

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        img_name = os.path.join(self.image_root,
                                self.csv['image'][idx]+'.jpg')
        sample = Image.open(img_name)
        target = self.csv['target'][idx]

        sample = self.transform(sample)

        return sample, target

def blood_noniid(numOfAgents, data, batch_size):
    """
        Function to divide the bloodmnist among clients 

        Input: 
            numOfAgents (int): Number of Agents (Clients)
            data: dataset to be divided 
            batch_size (int)

    
        Return: 
            datasets for agents, Loaders for agents , datasets for visualization

    """
    # static way of creating non iid data, to change the distribution change the index of p in
    # the for loop 
    nonIID_tensors = [[] for i in range(numOfAgents)]  
    nonIID_labels = [[] for i in range(numOfAgents)]  
    agents = np.arange(0,numOfAgents)
    c = 0
    p = np.ones((numOfAgents))
    xx = 0
    for i in data:
        xx+=1
        p = np.ones((numOfAgents))
        if float(i[1]) == 0:
            p[0] = numOfAgents
            p[1] = numOfAgents
            p[2] = numOfAgents
        if float(i[1]) == 1:
            p[0] = numOfAgents
            p[1] = numOfAgents
            p[2] = numOfAgents
        if float(i[1]) == 2:
            p[3] = numOfAgents
            p[5] = numOfAgents
            p[0] = numOfAgents
        if float(i[1]) == 3:
            p[0] = numOfAgents
            p[4] = numOfAgents
            p[5] = numOfAgents
        if float(i[1]) == 4:
            p[3] = numOfAgents
            p[4] = numOfAgents
            p[5] = numOfAgents
        if float(i[1]) == 5:
            p[3] = numOfAgents
            p[4] = numOfAgents
            p[5] = numOfAgents
        if float(i[1]) == 6:
            p[4] = numOfAgents
            p[5] = numOfAgents
            p[5] = numOfAgents
        if float(i[1]) == 7:
            p[0] = numOfAgents
            p[1] = numOfAgents
            p[2] = numOfAgents
        p = p / np.sum(p)
        j = np.random.choice(agents, p = p)
        nonIID_tensors[j].append(i[0])
        nonIID_labels[j].append(torch.tensor(i[1]).reshape(1))
    
    dataset_vis = [[] for i in range(numOfAgents) ]
    for i in range(numOfAgents):
        dataset_vis[i].append((torch.stack(nonIID_tensors[i]),torch.cat(nonIID_labels[i])))
    
    dataset_agents = [[] for i in range(numOfAgents) ]
    for agent in range(numOfAgents): 
        im_ = dataset_vis[agent][0][0]
        lab_ =  dataset_vis[agent][0][1]
        for im, lab in zip(im_, lab_):
            dataset_agents[agent].append((im, lab))

    dataset_loaders = [DataLoader(dataset_agents[i], batch_size=batch_size, shuffle=True, num_workers=8) for i in range(numOfAgents)]
    
    return dataset_agents, dataset_loaders, dataset_vis